{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de6281c7e6bb455b93f45fbaf6ce2567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abf9a9f59eca4d149355bf8396aa14cb",
              "IPY_MODEL_de21e4d50ab14e9ba1c786aa9d40ff1b",
              "IPY_MODEL_d091356d60b24349bfd3d4b5d51f0a94"
            ],
            "layout": "IPY_MODEL_98b8e5f6b10f4afb988d5cb532dd2513"
          }
        },
        "abf9a9f59eca4d149355bf8396aa14cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f268afc5f997457eb6c9b3d421794ede",
            "placeholder": "​",
            "style": "IPY_MODEL_817f1cb63f1e4654935840f339637500",
            "value": "Map: 100%"
          }
        },
        "de21e4d50ab14e9ba1c786aa9d40ff1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10e586d30c145b395a5e5b1ecc9e40b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a95ae5c6bffc4ff98dac01ef0b3aa300",
            "value": 100
          }
        },
        "d091356d60b24349bfd3d4b5d51f0a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8252891958da4aac95533d9680c801ee",
            "placeholder": "​",
            "style": "IPY_MODEL_bfad6f20198943fd887ab632ad4deb5f",
            "value": " 100/100 [00:00&lt;00:00, 1625.02 examples/s]"
          }
        },
        "98b8e5f6b10f4afb988d5cb532dd2513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f268afc5f997457eb6c9b3d421794ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "817f1cb63f1e4654935840f339637500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d10e586d30c145b395a5e5b1ecc9e40b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95ae5c6bffc4ff98dac01ef0b3aa300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8252891958da4aac95533d9680c801ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfad6f20198943fd887ab632ad4deb5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NastasiaMazur/Finance-Sentiment-Analysis/blob/main/distilbert_base_uncased_FinanceInc_auditor_sentiment__UPDATED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downstream Task: Sentiment Analysis\n",
        "\n",
        "Model: **distilbert-base-uncased**\n",
        "\n",
        "Dataset: **FinanceInc/auditor_sentiment**"
      ],
      "metadata": {
        "id": "e_vqCL24v9Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Activate GPU and Install Dependencies"
      ],
      "metadata": {
        "id": "yBNlvrYVVFkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check if GPU is available\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efuwmro3VSCg",
        "outputId": "52140285-24c4-49a4-a66c-e22960e0a7c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL_rW6LPouoz",
        "outputId": "5ea39eda-c7d9-4082-9d06-da5edeb24948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from bertviz) (1.34.68)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2023.12.25)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.4.99)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.68 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.34.68)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (0.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.68->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.68->boto3->bertviz) (1.16.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install bertviz transformers\n",
        "!pip install transformers[torch]\n",
        "#!apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conntext Google Drive so data can be stored there\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "QNGfCNFHo6JR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5215507-5b07-426b-c068-81a236c4207f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preprocess data"
      ],
      "metadata": {
        "id": "KvLcsFqZV7r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "from datasets import load_dataset\n",
        "finance_dataset = load_dataset(\"FinanceInc/auditor_sentiment\")"
      ],
      "metadata": {
        "id": "g2XpGCkIoMw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc1553c-d54c-443d-c32f-7f3d31468cfb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a smaller training dataset for faster training times\n",
        "from datasets import DatasetDict\n",
        "\n",
        "small_finance_dataset = DatasetDict(\n",
        "    train=finance_dataset['train'].shuffle(seed=24).select(range(500)), # for training\n",
        "    val=finance_dataset['train'].shuffle(seed=24).select(range(500, 600)), #  for validation\n",
        "    test=finance_dataset['train'].shuffle(seed=24).select(range(600, 700)) # for testing\n",
        ")"
      ],
      "metadata": {
        "id": "Ri0_OFKOo5ek"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_finance_dataset"
      ],
      "metadata": {
        "id": "d9OQdpzvp2NT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50870462-8c87-4e75-c72b-80b8c21b2d6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_finance_dataset['train'][:5]"
      ],
      "metadata": {
        "id": "159GyODfqjw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681d3117-0510-4d92-b6ab-3381736d23ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': ['FCC Chairman Kevin Martin said that fair play required extending the same deregulatory rules to the digital subscriber lines that telecom providers use for broadband networks .',\n",
              "  'Metso Foundries Jyvaskyla Oy will discontinue production on this line by 30 September 2008 , the company said .',\n",
              "  'Finnish business software group AffectoGenimap Oyj said its net profit halved to 1.2 mln euro ( $ 1.5 mln ) in the first nine months of 2006 from 2.2 mln euro ( $ 2.8 mln ) in the same period of 2005 .',\n",
              "  'Finnish financial software developer Basware Oyj said today it will provide its invoice automation ( IA ) solution to an unnamed major retail company in the USA in a deal , worth more than EUR300 ,000 .',\n",
              "  'According to the company , a decision in the issue will be made in the summer of 2010 , at the earliest , and in the summer of 2011 , at the latest .'],\n",
              " 'label': [1, 1, 0, 2, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set DistilBERT tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "print(tokenizer)\n",
        "print(len(tokenizer))"
      ],
      "metadata": {
        "id": "kESphrzIpSvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3823e589-644f-45f0-d1f7-89f626afda46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=True, truncation=True)\n",
        "\n",
        "small_tokenized_dataset = small_finance_dataset.map(tokenize_function, batched=True, batch_size=16)\n",
        "small_tokenized_dataset = small_tokenized_dataset.remove_columns([\"sentence\"])\n",
        "small_tokenized_dataset = small_tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "small_tokenized_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "eISDmxbhqpfi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "de6281c7e6bb455b93f45fbaf6ce2567",
            "abf9a9f59eca4d149355bf8396aa14cb",
            "de21e4d50ab14e9ba1c786aa9d40ff1b",
            "d091356d60b24349bfd3d4b5d51f0a94",
            "98b8e5f6b10f4afb988d5cb532dd2513",
            "f268afc5f997457eb6c9b3d421794ede",
            "817f1cb63f1e4654935840f339637500",
            "d10e586d30c145b395a5e5b1ecc9e40b",
            "a95ae5c6bffc4ff98dac01ef0b3aa300",
            "8252891958da4aac95533d9680c801ee",
            "bfad6f20198943fd887ab632ad4deb5f"
          ]
        },
        "outputId": "dd66998e-a705-4479-c896-17f83e73de9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de6281c7e6bb455b93f45fbaf6ce2567"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_tokenized_dataset['train'][0:2]\n"
      ],
      "metadata": {
        "id": "kciIFnHSuJsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d310298-a11e-4cc6-e6b1-11a4d947d636"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': tensor([1, 1]),\n",
              " 'input_ids': tensor([[  101, 14420,  3472,  4901,  3235,  2056,  2008,  4189,  2377,  3223,\n",
              "           8402,  1996,  2168,  4315, 13910, 20350,  2100,  3513,  2000,  1996,\n",
              "           3617,  4942, 29234,  2099,  3210,  2008, 18126, 11670,  2224,  2005,\n",
              "          19595,  6125,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0],\n",
              "         [  101, 15253,  2080,  2179,  5134,  1046,  2100, 12044,  4801,  2721,\n",
              "           1051,  2100,  2097, 12532, 16778, 11231,  2063,  2537,  2006,  2023,\n",
              "           2240,  2011,  2382,  2244,  2263,  1010,  1996,  2194,  2056,  1012,\n",
              "            102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(small_tokenized_dataset['train'], batch_size=16)\n",
        "eval_dataloader = DataLoader(small_tokenized_dataset['val'], batch_size=16)"
      ],
      "metadata": {
        "id": "2P20kcPPuLWS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Training the model"
      ],
      "metadata": {
        "id": "nTFKHB-EqFJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import pipeline\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "7QqtFQtIuOxD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DistilBERT as our base model:\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
      ],
      "metadata": {
        "id": "MYdMqyZEqPIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6308aefb-5170-4427-88d4-1e27b29d8f2b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "num_training_steps = 3 * len(train_dataloader)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
      ],
      "metadata": {
        "id": "pBL0y4TIuQuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c6ab7b-4efd-4dae-f0b6-0b2301b3ed63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "aYWvMqWYuSkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfa4fc1-490c-4e42-dfa2-1af613b57891"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncomment if you want to log in to your Hugging Face account:"
      ],
      "metadata": {
        "id": "st-R5aojvRBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to your Hugging Face account\n",
        "# Get your API token here https://huggingface.co/settings/token\n",
        "#from huggingface_hub import notebook_login\n",
        "\n",
        "#notebook_login()"
      ],
      "metadata": {
        "id": "_es0nLyOrLYL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new Trainer with all the objects we constructed so far\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilroberta-base', num_labels=3)\n",
        "\n",
        "arguments = TrainingArguments(\n",
        "    output_dir=\"store_the_checkpoints_distilbert_3\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    lr_scheduler_type='cosine',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='loss',\n",
        "    greater_is_better=False,\n",
        "    seed=224\n",
        "    #push_to_hub=True, # uncomment to push into hugginhface hub\n",
        ")\n",
        "\n",
        "\n",
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=3,\n",
        "    early_stopping_threshold=0.0\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # calculates the accuracy\n",
        "    return {\"accuracy\": np.mean(predictions == labels)}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=arguments,\n",
        "    train_dataset=small_tokenized_dataset['train'],\n",
        "    eval_dataset=small_tokenized_dataset['val'], # change to test when you do your final evaluation!\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, None)\n",
        ")"
      ],
      "metadata": {
        "id": "W3YWCCXtuXAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb2c4e9-370b-4e87-9b99-a1f8bb40a058"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "xGjzgt6HuZgq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "268dce03-75f0-4983-be28-b8cbfb843113"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 01:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.965448</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.889382</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.891198</td>\n",
              "      <td>0.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.960480</td>\n",
              "      <td>0.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.983399</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.065786</td>\n",
              "      <td>0.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.002142</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.020725</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.040846</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.040170</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-32 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-64 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-96 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-128 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-160 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-192 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-224 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-256 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-288 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory store_the_checkpoints_distilbert_3/checkpoint-320 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=320, training_loss=0.6518671035766601, metrics={'train_runtime': 114.069, 'train_samples_per_second': 43.833, 'train_steps_per_second': 2.805, 'total_flos': 93543314763096.0, 'train_loss': 0.6518671035766601, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.predict(small_tokenized_dataset['val'])\n",
        "print(results)"
      ],
      "metadata": {
        "id": "zjDxZ2VBueBS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61e83430-8536-4ca7-e992-e84d7a2671b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionOutput(predictions=array([[-0.9883296 ,  1.0663089 , -0.19555055],\n",
            "       [-1.0075653 ,  1.0238501 , -0.20102467],\n",
            "       [-0.9743034 ,  0.8903042 , -0.10181137],\n",
            "       [-1.0141464 ,  1.1176709 , -0.28669825],\n",
            "       [-0.80501634,  0.5868265 ,  0.04448523],\n",
            "       [-1.0918534 ,  1.1999589 , -0.31343073],\n",
            "       [-1.1213168 ,  1.2949274 , -0.3600805 ],\n",
            "       [-1.0289601 ,  1.1206353 , -0.22335055],\n",
            "       [-1.0982958 ,  1.2857779 , -0.3293508 ],\n",
            "       [-0.7942334 ,  0.5759672 ,  0.04039393],\n",
            "       [-1.099818  ,  1.2173591 , -0.32070878],\n",
            "       [-1.0547999 ,  1.1025351 , -0.31002665],\n",
            "       [-0.96267444,  0.90857536, -0.12384115],\n",
            "       [-0.864079  ,  0.84005016, -0.1228763 ],\n",
            "       [-0.84884995,  0.7809959 , -0.10800491],\n",
            "       [-1.1136881 ,  1.2661328 , -0.30569682],\n",
            "       [-1.0974951 ,  1.2130656 , -0.2755209 ],\n",
            "       [-1.074966  ,  1.1995877 , -0.31873593],\n",
            "       [-1.0170207 ,  1.0441893 , -0.21396542],\n",
            "       [-0.97989994,  1.0250355 , -0.16959293],\n",
            "       [-1.0679694 ,  1.1132253 , -0.32637867],\n",
            "       [-0.982702  ,  0.9486906 , -0.17159545],\n",
            "       [-0.93059677,  0.8747715 , -0.14318566],\n",
            "       [-1.0716972 ,  1.1656047 , -0.262865  ],\n",
            "       [-0.9593712 ,  1.0093575 , -0.2115898 ],\n",
            "       [-1.0891672 ,  1.2401965 , -0.28351843],\n",
            "       [-1.0768687 ,  1.1609437 , -0.3382873 ],\n",
            "       [-1.0781913 ,  1.2628663 , -0.29205868],\n",
            "       [-0.9893171 ,  1.0281711 , -0.18235232],\n",
            "       [-1.004006  ,  1.1221474 , -0.3543454 ],\n",
            "       [-0.9404649 ,  0.9165534 , -0.12815598],\n",
            "       [-0.8598603 ,  0.69154304,  0.00860001],\n",
            "       [-1.0374317 ,  1.1029652 , -0.22009148],\n",
            "       [-0.9483748 ,  0.98417324, -0.19311884],\n",
            "       [-1.1307766 ,  1.387203  , -0.48797172],\n",
            "       [-1.0242814 ,  1.2124077 , -0.38031414],\n",
            "       [-1.0315602 ,  1.0343459 , -0.22868466],\n",
            "       [-1.0647656 ,  1.1329068 , -0.23317619],\n",
            "       [-1.036943  ,  1.2362227 , -0.33168966],\n",
            "       [-0.7769512 ,  0.54033375,  0.12594953],\n",
            "       [-1.0229659 ,  1.2282614 , -0.3008322 ],\n",
            "       [-0.9937028 ,  0.959849  , -0.12363717],\n",
            "       [-0.9875028 ,  0.94148093, -0.17797643],\n",
            "       [-1.0683153 ,  1.1635615 , -0.2732818 ],\n",
            "       [-0.9293957 ,  0.79033655, -0.05555562],\n",
            "       [-1.0870028 ,  1.2191814 , -0.30811545],\n",
            "       [-1.0448875 ,  1.1371    , -0.19740874],\n",
            "       [-0.9776991 ,  1.0575365 , -0.26652363],\n",
            "       [-0.7797766 ,  0.5746481 ,  0.02856656],\n",
            "       [-0.8672576 ,  0.6748322 , -0.05550619],\n",
            "       [-0.9891348 ,  1.0006726 , -0.21610127],\n",
            "       [-1.0136687 ,  1.1321157 , -0.25823608],\n",
            "       [-1.0036893 ,  1.0375552 , -0.20348954],\n",
            "       [-0.90489614,  0.8406656 , -0.08462891],\n",
            "       [-1.1166192 ,  1.2659836 , -0.3344479 ],\n",
            "       [-0.8614266 ,  0.6272137 ,  0.04353812],\n",
            "       [-1.097037  ,  1.2396467 , -0.3186234 ],\n",
            "       [-0.9887405 ,  0.9225988 , -0.11298694],\n",
            "       [-1.072045  ,  1.2612965 , -0.30759427],\n",
            "       [-1.0882068 ,  1.141885  , -0.26936764],\n",
            "       [-1.1059549 ,  1.2440616 , -0.35649332],\n",
            "       [-1.0131708 ,  0.97499603, -0.18468496],\n",
            "       [-1.0350076 ,  1.2707877 , -0.38525084],\n",
            "       [-0.99779356,  0.9729718 , -0.15396148],\n",
            "       [-1.0287328 ,  1.1630964 , -0.27617997],\n",
            "       [-0.94404274,  0.91975844, -0.12960292],\n",
            "       [-1.0434498 ,  1.0785605 , -0.19714135],\n",
            "       [-0.9261869 ,  0.84231275, -0.07291752],\n",
            "       [-1.0553595 ,  1.1584398 , -0.33593094],\n",
            "       [-0.89949316,  0.83897036, -0.12307755],\n",
            "       [-1.0932139 ,  1.2646503 , -0.3119156 ],\n",
            "       [-0.99269605,  0.98476994, -0.15980494],\n",
            "       [-0.9506897 ,  0.91460896, -0.15812404],\n",
            "       [-1.1068897 ,  1.2818639 , -0.3494639 ],\n",
            "       [-1.0775669 ,  1.1562914 , -0.2703886 ],\n",
            "       [-0.90318596,  0.9446362 , -0.1927151 ],\n",
            "       [-1.0948137 ,  1.2511852 , -0.3332729 ],\n",
            "       [-1.033644  ,  1.1280555 , -0.2383305 ],\n",
            "       [-1.0236071 ,  1.1026518 , -0.22540386],\n",
            "       [-1.003002  ,  1.1705339 , -0.26962844],\n",
            "       [-1.0122288 ,  1.098353  , -0.18839629],\n",
            "       [-0.9901062 ,  1.0661956 , -0.2483564 ],\n",
            "       [-1.0661651 ,  1.2141073 , -0.29364184],\n",
            "       [-1.1147879 ,  1.2535367 , -0.3489891 ],\n",
            "       [-1.0360781 ,  1.2355545 , -0.37711397],\n",
            "       [-1.058939  ,  1.1748972 , -0.20375206],\n",
            "       [-1.0709715 ,  1.2350843 , -0.3799026 ],\n",
            "       [-1.122361  ,  1.3114772 , -0.38157436],\n",
            "       [-0.7590736 ,  0.49303326,  0.09431686],\n",
            "       [-0.9503391 ,  1.1474963 , -0.3515388 ],\n",
            "       [-1.0156734 ,  1.2027131 , -0.29219007],\n",
            "       [-1.0728859 ,  1.1906503 , -0.31172013],\n",
            "       [-0.9919769 ,  1.0522549 , -0.1947059 ],\n",
            "       [-1.0752959 ,  1.1574475 , -0.29697365],\n",
            "       [-0.9565183 ,  1.0333204 , -0.29691073],\n",
            "       [-1.065287  ,  1.1418121 , -0.28418097],\n",
            "       [-1.0113891 ,  1.0577116 , -0.1961797 ],\n",
            "       [-1.008823  ,  1.21024   , -0.27834737],\n",
            "       [-0.87704796,  0.7369827 , -0.05078236],\n",
            "       [-0.84325767,  0.6883576 , -0.00878942]], dtype=float32), label_ids=array([0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2,\n",
            "       1, 1, 1, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1,\n",
            "       0, 2, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 0, 0, 1, 2, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0]), metrics={'test_loss': 0.8893824815750122, 'test_accuracy': 0.66, 'test_runtime': 0.3038, 'test_samples_per_second': 329.196, 'test_steps_per_second': 23.044})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_str = \"The company's strong quarterly earnings report resulted in a surge in stock prices, reflecting investor confidence in its future prospects.\"\n",
        "\n",
        "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(\"store_the_checkpoints_distilbert_3/checkpoint-320\") # pass checkpoint to the model\n",
        "model_inputs = tokenizer(test_str, return_tensors=\"pt\")\n",
        "\n",
        "prediction = torch.argmax(fine_tuned_model(**model_inputs).logits)\n",
        "print([\"NEGATIVE\", \"POSITIVE\", \"NEUTRAL\"][prediction])"
      ],
      "metadata": {
        "id": "q_QeKTlHu8bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5061d75-430e-4361-fc50-74c94e26b500"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEUTRAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.predict(small_tokenized_dataset['test'])\n",
        "print(results)"
      ],
      "metadata": {
        "id": "Fg-fLh12vEB1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e1162f9-4cee-4de3-b969-c60ebe3af4ab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionOutput(predictions=array([[-1.0096958 ,  1.1633741 , -0.36124346],\n",
            "       [-0.91207147,  0.8892056 , -0.13056034],\n",
            "       [-1.1081475 ,  1.2072246 , -0.31708384],\n",
            "       [-1.029619  ,  1.1084139 , -0.2846068 ],\n",
            "       [-0.83741546,  0.6304093 ,  0.07402465],\n",
            "       [-1.0062007 ,  1.0679936 , -0.21069936],\n",
            "       [-0.85467976,  0.6351199 ,  0.03737538],\n",
            "       [-1.0081426 ,  1.1209158 , -0.26125833],\n",
            "       [-0.89479905,  0.77574944, -0.06085769],\n",
            "       [-1.0068668 ,  1.0513003 , -0.17720805],\n",
            "       [-1.031467  ,  1.1454219 , -0.25403574],\n",
            "       [-1.059274  ,  1.2410553 , -0.30050936],\n",
            "       [-1.0226493 ,  1.153878  , -0.3029826 ],\n",
            "       [-1.0365709 ,  1.0695225 , -0.21671854],\n",
            "       [-0.8722071 ,  0.746572  , -0.0494629 ],\n",
            "       [-1.0736469 ,  1.0528276 , -0.2051871 ],\n",
            "       [-0.8821162 ,  0.7152684 , -0.02819435],\n",
            "       [-1.1030569 ,  1.3090581 , -0.35124192],\n",
            "       [-1.0420303 ,  1.0877094 , -0.24052937],\n",
            "       [-0.93578243,  0.97898924, -0.19884661],\n",
            "       [-0.99928373,  1.0087117 , -0.19323146],\n",
            "       [-1.0156314 ,  1.1262417 , -0.23276919],\n",
            "       [-0.92260003,  0.9006971 , -0.0936878 ],\n",
            "       [-0.9619997 ,  0.87417865, -0.10910869],\n",
            "       [-1.00381   ,  1.0672083 , -0.21777697],\n",
            "       [-1.030661  ,  1.0333275 , -0.2521617 ],\n",
            "       [-0.88945866,  0.70175034, -0.04274441],\n",
            "       [-1.1136931 ,  1.2932382 , -0.30368656],\n",
            "       [-1.0367633 ,  1.0934945 , -0.22684933],\n",
            "       [-0.9952124 ,  0.9621036 , -0.18512015],\n",
            "       [-0.93904746,  0.85437435, -0.10272062],\n",
            "       [-0.9712094 ,  1.0801477 , -0.29060408],\n",
            "       [-1.0326139 ,  1.0217223 , -0.22337776],\n",
            "       [-0.87560683,  0.7683973 , -0.03187445],\n",
            "       [-1.0809968 ,  1.2222239 , -0.31227458],\n",
            "       [-1.0755147 ,  1.1093553 , -0.24656574],\n",
            "       [-1.0385655 ,  1.0469265 , -0.20855571],\n",
            "       [-0.8066729 ,  0.64455414, -0.02656555],\n",
            "       [-1.0191383 ,  1.1727539 , -0.31264445],\n",
            "       [-1.1278994 ,  1.3450866 , -0.3738031 ],\n",
            "       [-0.80018896,  0.5477161 ,  0.05111254],\n",
            "       [-0.9879854 ,  1.0899082 , -0.24479766],\n",
            "       [-0.9759647 ,  0.9415843 , -0.2251042 ],\n",
            "       [-1.0361986 ,  1.1974051 , -0.28612584],\n",
            "       [-1.1163831 ,  1.2372155 , -0.30832192],\n",
            "       [-0.9595961 ,  0.9872399 , -0.14678882],\n",
            "       [-1.0643411 ,  1.2762301 , -0.37226912],\n",
            "       [-0.9272121 ,  1.0544742 , -0.31608766],\n",
            "       [-1.0384649 ,  1.0846041 , -0.16736956],\n",
            "       [-0.8778282 ,  0.80087155, -0.01781548],\n",
            "       [-0.9767503 ,  0.91889864, -0.13167359],\n",
            "       [-1.0122528 ,  1.0346237 , -0.20033237],\n",
            "       [-0.9747968 ,  1.0943061 , -0.29072186],\n",
            "       [-1.0394528 ,  1.092226  , -0.24550724],\n",
            "       [-1.0165609 ,  1.0172883 , -0.28381273],\n",
            "       [-0.97976404,  1.1102062 , -0.28883988],\n",
            "       [-0.8044129 ,  0.60878074,  0.11556126],\n",
            "       [-1.1090562 ,  1.1441833 , -0.31762126],\n",
            "       [-1.0017164 ,  0.95742357, -0.12500149],\n",
            "       [-1.0761039 ,  1.2495522 , -0.3486127 ],\n",
            "       [-1.0152354 ,  1.0334896 , -0.19175681],\n",
            "       [-1.0523382 ,  1.0791676 , -0.25720248],\n",
            "       [-1.0246516 ,  1.1903591 , -0.3057743 ],\n",
            "       [-1.0769259 ,  1.1672491 , -0.26140466],\n",
            "       [-0.8718826 ,  0.68072087,  0.00444759],\n",
            "       [-0.98296744,  1.0726479 , -0.22137022],\n",
            "       [-0.89545155,  0.968034  , -0.25038984],\n",
            "       [-0.9919126 ,  0.9905008 , -0.17886484],\n",
            "       [-0.95634866,  1.1509036 , -0.2436841 ],\n",
            "       [-1.0769873 ,  1.1419356 , -0.23457989],\n",
            "       [-1.0524942 ,  1.0972112 , -0.21275531],\n",
            "       [-1.0737379 ,  1.282242  , -0.34880874],\n",
            "       [-1.0946541 ,  1.3030959 , -0.3481476 ],\n",
            "       [-1.0531088 ,  1.1084336 , -0.25514132],\n",
            "       [-1.1154752 ,  1.140017  , -0.31944877],\n",
            "       [-1.0569993 ,  1.1689341 , -0.2758097 ],\n",
            "       [-0.99437433,  0.96493536, -0.0959793 ],\n",
            "       [-1.0137386 ,  1.0960474 , -0.19308068],\n",
            "       [-0.8366488 ,  0.6752941 ,  0.00456935],\n",
            "       [-1.0408771 ,  1.277114  , -0.3690333 ],\n",
            "       [-0.8566306 ,  0.77006423, -0.0488176 ],\n",
            "       [-1.075832  ,  1.2046703 , -0.31278196],\n",
            "       [-1.0091711 ,  1.1692281 , -0.34594986],\n",
            "       [-1.0360664 ,  1.1008651 , -0.19688152],\n",
            "       [-1.0106254 ,  1.1091546 , -0.2630592 ],\n",
            "       [-0.9900645 ,  1.1092459 , -0.31090122],\n",
            "       [-1.063447  ,  1.2221804 , -0.33812928],\n",
            "       [-1.0343993 ,  1.2296944 , -0.32674226],\n",
            "       [-0.8329024 ,  0.6084368 ,  0.0678072 ],\n",
            "       [-1.0200629 ,  1.1311442 , -0.27059475],\n",
            "       [-1.0895681 ,  1.0747933 , -0.19990563],\n",
            "       [-0.9517436 ,  0.9203581 , -0.10222231],\n",
            "       [-1.0977468 ,  1.2298492 , -0.37530708],\n",
            "       [-0.9413943 ,  0.9878234 , -0.17583708],\n",
            "       [-1.0624918 ,  1.242404  , -0.33897766],\n",
            "       [-0.8787294 ,  0.7351379 , -0.0262875 ],\n",
            "       [-0.8257561 ,  0.66416544,  0.00483859],\n",
            "       [-1.094044  ,  1.2611027 , -0.38164565],\n",
            "       [-0.9848071 ,  1.091341  , -0.2712489 ],\n",
            "       [-1.0185908 ,  1.1280617 , -0.35412776]], dtype=float32), label_ids=array([1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
            "       2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 2, 1, 1, 0, 1, 1, 2,\n",
            "       1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 2, 2, 1, 2, 0, 2,\n",
            "       2, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
            "       0, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1]), metrics={'test_loss': 0.892271876335144, 'test_accuracy': 0.6, 'test_runtime': 0.193, 'test_samples_per_second': 518.148, 'test_steps_per_second': 36.27})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_finance_dataset['test'][5]"
      ],
      "metadata": {
        "id": "OFPIjegkvF8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc6a48f-5ba3-470b-d3dc-5bf145f7b526"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': \"The government has instead proposed an exchange of the state 's stake in LMT to TeliaSonera 's stake in Lattelecom .\",\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(\"store_the_checkpoints_distilbert_3/checkpoint-320\")\n",
        "\n",
        "model_inputs = tokenizer(small_tokenized_dataset['test']['sentence'], padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "outputs = fine_tuned_model(**model_inputs, output_hidden_states=True)"
      ],
      "metadata": {
        "id": "MEHrZagOvM40"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "path = \"/content/drive/MyDrive/results_vis_distilbert_2\"\n",
        "layer = 0\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "while layer in range(len(outputs['hidden_states'])):\n",
        "    if not os.path.exists(path+'/layer_' + str(layer)):\n",
        "        os.mkdir(path+'/layer_' + str(layer))\n",
        "\n",
        "    tensors = []\n",
        "    labels = []\n",
        "\n",
        "    for example in range(len(outputs['hidden_states'][layer])):\n",
        "        sp_token_position = 0\n",
        "        for token in model_inputs['input_ids'][example]:\n",
        "            if token != 0:\n",
        "                sp_token_position += 1\n",
        "            else:\n",
        "                tensor = outputs['hidden_states'][layer][example][sp_token_position]\n",
        "                tensors.append(tensor)\n",
        "                label = [small_tokenized_dataset['test']['sentence'][example], str(small_tokenized_dataset['test']['label'][example])]\n",
        "                labels.append(label)\n",
        "                break\n",
        "\n",
        "    #print(\"Length of tensors:\", len(tensors))\n",
        "    #print(\"Length of labels:\", len(labels))\n",
        "\n",
        "    global_step = layer  # Set global_step to the current layer number\n",
        "    writer = SummaryWriter(path+'/layer_' + str(layer))\n",
        "    writer.add_embedding(torch.stack(tensors), metadata=labels, metadata_header=['Sentence','Emotion'], global_step=global_step)\n",
        "\n",
        "    layer += 1\n"
      ],
      "metadata": {
        "id": "1IKmuA5KbIyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a36e692-568d-4f72-9c77-b66ab650052b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " TensorFlow Embedding Projector [API](https://projector.tensorflow.org/)."
      ],
      "metadata": {
        "id": "4XyHs4Ymd4Bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________________\n",
        "\n"
      ],
      "metadata": {
        "id": "HEFp35-ZWDY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid AssertionError:(#labels should equal with #data points) and ensure that labels are extracted consistently with the corresponding tensors ensure that you're extracting labels consistently with how you're extracting tensors.\n",
        "\n",
        "To avoid a warning: (Embedding dir exists, did you set global_step for add_embedding()? ) add \"global_step = layer\""
      ],
      "metadata": {
        "id": "8ioQg3CTefTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Analyzing new data with the model"
      ],
      "metadata": {
        "id": "p3w-ag8XswRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use pipeline (uncomment a cell with huggingface above):"
      ],
      "metadata": {
        "id": "smI7RYC7uXYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the model to the Hub\n",
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "IzhYIWNMsx1y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "b3d929c9-c23d-4a66-ff63-8f49570bebd0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c2297e05a2ce>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Upload the model to the Hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   3859\u001b[0m         \u001b[0;31m# In case the user calls this method with args.push_to_hub = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_model_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3861\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hf_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3863\u001b[0m         \u001b[0;31m# Needs to be executed on all processes for TPU training, but will only save on the processed determined by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36minit_hf_repo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3692\u001b[0m             \u001b[0mrepo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_model_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3694\u001b[0;31m         \u001b[0mrepo_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_private_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3695\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_model_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_in_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3160\u001b[0m             \u001b[0;31m# See https://github.com/huggingface/huggingface_hub/pull/733/files#r820604472\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3161\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lfsmultipartthresh\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lfsmultipartthresh\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3162\u001b[0;31m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_hf_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3164\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36m_build_hf_headers\u001b[0;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   8189\u001b[0m             \u001b[0;31m# Cannot do `token = token or self.token` as token can be `False`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8190\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8191\u001b[0;31m         return build_hf_headers(\n\u001b[0m\u001b[1;32m   8192\u001b[0m             \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8193\u001b[0m             \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_write_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mbuild_hf_headers\u001b[0;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Get auth token to send\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtoken_to_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0m_validate_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_to_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_write_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Combine headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36m_validate_token_to_send\u001b[0;34m(token, is_write_action)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0;34m\"Token is required (write-access action) but no token found. You need\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;34m\" to provide a token or be logged in to Hugging Face with\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inferences with your new model using Pipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "sentiment_model = pipeline(model=\"\") # Add your saved mode in \"\"\n",
        "\n",
        "sentiment_model([\"The company's strong quarterly earnings report resulted in a surge in stock prices, reflecting investor confidence in its future prospects.\"])"
      ],
      "metadata": {
        "id": "Yp_sdpcks22f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}